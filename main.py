import streamlit as st
import plotly.graph_objects as go

# PIE理論の円グラフを描画する関数
def plot_pie_chart():
    # PIE理論のデータ
    labels = ['パフォーマンス (10%)', 'イメージ (30%)', '露出 (60%)']
    sizes = [10, 30, 60]

    # Plotlyを使った円グラフ
    fig = go.Figure(data=[go.Pie(labels=labels, values=sizes, hole=.3)])
    
    # グラフのラベルやサイズ、マージンを調整
    fig.update_traces(textposition='outside', textinfo='label+percent', pull=[0, 0, 0.1])  # ラベルを外側に配置
    fig.update_layout(title_text="ハーヴィー・コールマンのPIE理論", margin=dict(t=20, b=20, l=10, r=10), height=350, showlegend=False)  # グラフの高さと余白を調整
    
    return fig

# Streamlitレイアウト
st.markdown("---")

# タイトル
st.markdown("""
<h1 style='font-size:18px; margin-bottom: 5px;'>ハーヴィー・コールマンのPIE理論</h1>
""", unsafe_allow_html=True)

# 折りたたみセクションで詳細を表示
with st.expander("詳細を表示"):
    # 上部2カラムレイアウトを作成
    col1, col2 = st.columns([1, 1])  # カラム幅を均等に調整
    
    # 左側に円グラフを表示
    with col1:
        st.plotly_chart(plot_pie_chart(), use_container_width=True)  # グラフの幅をカラムいっぱいに
    
    # 右側に説明を表示
    with col2:
        st.subheader("説明")
        st.markdown("""
        <p style="font-size:12px; line-height:1.5; margin-top: -10px; margin-bottom: 5px;">
        <strong>パフォーマンス: 成功の基盤 (10%)</strong><br>
        - パフォーマンスはキャリアの進展において重要であり、全体の10%を占めています。<br>
        - 仕事をうまくこなすことは必要ですが、それだけでは成長の限界があります。<br><br>
        <strong>イメージ: 認識が力 (30%)</strong><br>
        - 他者からの認識がキャリアの成長に30%影響します。<br>
        - ポジティブでプロフェッショナルなイメージを築くことが大切です。<br><br>
        <strong>露出: 能力の発揮 (60%)</strong><br>
        - 露出はキャリア進展の60%を占めています。<br>
        - 自分の能力を示し、適切な人々に見てもらうことが成功の鍵です。
        </p>
        """, unsafe_allow_html=True)

    # 下部に1カラムレイアウトで情報ボックスを表示
    st.markdown("""
    <div style="background-color: #f0f8ff; padding: 8px; border-radius: 5px; border-left: 5px solid #2196f3; margin-top: 15px; margin-bottom: 0px;">
        <div style="font-size:12px; line-height:1.5;">
        「PIEの法則」は、キャリアを成功させるために重要な3つの要素を表すフレームワークで、
        特に外資系企業やビジネス界での出世や成功において強調されることがあります。
        この法則は以下の3つの要素から成り立っています：<br><br>
        <strong>P</strong> (Performance) - 業績、パフォーマンス
        自分の仕事の成果や、仕事での達成度を意味します。どれだけ良い結果を出し、貢献しているかが重要視されますが、これは出世においては全体の一部に過ぎません。<br><br>
        <strong>I</strong> (Image) - イメージ、印象
        自分が周りからどう見られているか、どのような印象を与えているかがポイントです。プロフェッショナリズム、リーダーシップ、信頼性、自己ブランドの確立が含まれます。<br><br>
        <strong>E</strong> (Exposure) - 露出、知名度
        どれだけ多くの人に自分の存在を知ってもらっているか、また自分の業績やスキルがどれだけ広く認識されているかを示します。適切な人々とのネットワーク作りや、
        重要なプロジェクトに関与することなどがこれに含まれます。<br><br>
        このPIEの法則において、最も重視されるのは「Exposure（露出）」です。どれだけ優れたパフォーマンスを発揮しても、
        それが周りに認知されなければ、出世や昇進に繋がらないことが多いためです。
        PIEの法則は、自己ブランディングとネットワーキングの重要性を説いており、特に外資系企業では単に仕事をこなすだけではなく、
        自分の存在を効果的に周囲にアピールし、適切な人脈を築くことが求められます。
        </div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
<h1 style='font-size:18px; margin-bottom: 5px;'>参考サイト</h1>
""", unsafe_allow_html=True)
    st.markdown("""
1. [The Networking Institute]
(https://thenetworkinginstitute.com/media/networking/the-pie-theory-performance-image-and-exposure-in-career-progression/) （更新日：
July 21, 2023）
""")
    
    st.markdown("---")


import streamlit as st
import pandas as pd

# Streamlitレイアウト
st.markdown("---")

# タイトル
st.markdown("""
<h1 style='font-size:18px; margin-bottom: 5px;'>今までのAIとAGI、ASIとの違い</h1>
""", unsafe_allow_html=True)

with st.expander("詳細を表示"):
    # 説明文
    st.write("""
    従来のAIは、特定のタスクや問題に特化したものであり、一つのプログラムやアルゴリズムで動作しており、限定的な範囲での活動が主でした。
    一方、AGIは汎用的な知能を持つことで複数のタスクに対応できる、人間のような柔軟性を持っています。
    さらにASIは人間の知能をはるかに超えるため、未知のタスクも解決できるようになります。
    """)
    
    # テーブルデータの作成
    data = {
        '': ['従来のAI', 'AGI', 'ASI'],
        'タスクの特化': [
            '画像認識や音声認識など、特定の領域に限定してタスクを実行',
            '複数タスクに対応できる汎用的な能力がある',
            '未知のタスクや複雑な問題も自己進化により解決できる'
        ],
        '学習能力': [
            'あらかじめプログラムされた膨大なデータからルールやパターンを学習',
            'データや経験から学習し、新たな情報を踏まえて適切な判断を行う',
            '自己学習と自己進化が可能で、どんな知識も効率的に獲得し応用する'
        ],
        '柔軟性': [
            'あらかじめ設計された手法に基づいてタスクを実行',
            '新しい問題へのアプローチや解決策を見出すことができる',
            '未知の状況や問題に立ち向かう能力がある'
        ],
        '自己進化': [
            '範囲内でのタスクを実行（自己進化はしない）',
            '経験から学び、新たな情報を取り入れて能力を向上させる（自己進化は限定的）',
            '人間の監督なしに自己改善と自己進化を遂行することができる'
        ]
    }
    
    # データをデータフレームに変換
    df = pd.DataFrame(data)
    
    # テーブルの表示
    st.table(df)

# Streamlitレイアウト
st.markdown("---")

# タイトル
st.markdown("""
<h1 style='font-size:18px; margin-bottom: 5px;'>生成AIのリスク</h1>
""", unsafe_allow_html=True)

with st.expander("詳細を表示"):
    # 説明文
    st.write("""
生成AIのリスクは、利用者、提供者、社会全体のそれぞれの立場から異なる視点で発生します。
利用者はプライバシーや誤情報のリスクに直面し、提供者は責任の所在や知的財産問題を考慮する必要があります。
さらに、社会全体としては、デジタル・デバイドの拡大や労働市場への影響、社会的な偏見の再生産が懸念されます。
これらのリスクを適切に管理するためには、技術開発に合わせたガバナンスと教育が求められます。
    """)
# データを辞書で作成
    data = {
        "リスクの種類": ["誤情報", "情報漏洩", "依存とスキル低下", "責任不明確", "権利侵害（知的財産権）", "セキュリティリスク", "偏見強化", "労働市場への影響", "規制の遅れ"],
        "利用者の立場からのリスク": [
            "誤った情報を信じてしまうリスク", 
            "個人情報や機密データの漏洩リスク", 
            "AIへの依存による人間のスキル低下", 
            "-", 
            "-", 
            "-", 
            "偏見や差別的な情報を無意識に受け入れるリスク", 
            "-", 
            "-"
        ],
        "提供者の立場からのリスク": [
            "誤情報に対する法的責任が問われるリスク", 
            "データの不正利用による責任", 
            "-", 
            "有害情報や誤情報の責任が不明確", 
            "AIが他者の著作権を侵害するリスク", 
            "AIシステムがハッキングされるリスク", 
            "バイアスのあるモデル提供リスク", 
            "AIによる業務自動化の影響", 
            "規制の遅れによる対策不足"
        ],
        "社会の立場からのリスク": [
            "社会全体での情報混乱リスク", 
            "プライバシー保護規制の遅れ", 
            "クリエイティブ力の低下リスク", 
            "法的責任の曖昧さ", 
            "著作権問題の社会的影響", 
            "セキュリティ事故による社会的混乱", 
            "社会的偏見や分断の強化", 
            "失業や職業の変化リスク", 
            "法的枠組みが追いつかないリスク"
        ]
    }

    # DataFrameを作成
    df = pd.DataFrame(data)
    
    # Streamlitで表を表示
    st.title("生成AIに関連するリスク一覧")
    st.table(df)

st.markdown("---")

# タイトル
st.markdown("""
<h1 style='font-size:18px; margin-bottom: 5px;'>生成AIにおけるオプトアウトとサニタイズの重要性</h1>
""", unsafe_allow_html=True)

with st.expander("詳細を表示"):
    # オプトアウトのセクション
    st.header("1. オプトアウト")
    st.write("""
    **定義**: ユーザーが、自分のデータが生成AIシステムで利用されることを拒否する権利。
    
    **重要性**: 個人情報が無断で使用されると、プライバシーが侵害されるリスクが高まります。オプトアウトにより、データの透明性と倫理的な使用を確保できます。
    
    **効果**: ユーザーが自分のデータがAIにどのように使用されるかを理解し、拒否する権利を行使することで、情報漏洩やプライバシー侵害のリスクを軽減できます。
    """)
    
    # サニタイズのセクション
    st.header("2. サニタイズ（データサニタイズ）")
    st.write("""
    **定義**: サニタイズは、データから個人を特定できる情報（PII）や機密情報を削除・無効化するプロセスです。
    
    **重要性**: AIの訓練データに個人情報が含まれている場合、そのデータが生成物に影響を与え、権利侵害やプライバシーリスクを引き起こす可能性があります。
    
    **効果**: データを適切にサニタイズすることで、生成AIがプライバシーに配慮したデータを使用し、誤用や漏洩を防ぎます。これにより、AIが出力する情報の信頼性も高まります。
    """)
    
    # まとめのセクション
    st.header("まとめ")
    st.write("""
    オプトアウトは、ユーザーがデータ利用を拒否する権利を行使する仕組みであり、プライバシー保護のために重要です。サニタイズは、AIが使用するデータから個人を特定できる情報を削除し、安全性を確保するプロセスです。これらの手法を導入することで、生成AIに関わるリスクを大幅に軽減し、倫理的かつ安全なAI利用が可能になります。
    """)

    st.markdown("""
    <div style="background-color: #f0f8ff; padding: 8px; border-radius: 5px; border-left: 5px solid #2196f3; margin-top: 15px; margin-bottom: 0px;">
情報を消す、情報を抽象化する、そして表現の適正化は、特にデータ保護や生成AIの使用において非常に重要なプロセスです。
これらの要素は、プライバシー保護や情報の正確さを保つために不可欠です。それぞれの役割についてもう少し詳しく見てみましょう。

<strong>1. 情報を消す</strong><br>
重要性: 不必要な個人情報や機密データを削除することは、セキュリティやプライバシー保護において最も基本的な措置です。データが意図せず公開されたり、AIの訓練データとして使われたりするリスクを防ぐために、適切なタイミングで情報を消すことが必要です。
具体例: クレジットカード番号や個人の住所など、不要となった情報を安全に消去することで、悪用や漏洩のリスクを回避します。<br><br>
<strong>2. 情報を抽象化する</strong><br>
重要性: 情報の抽象化は、個人や特定の事象を特定できないようにデータを加工するプロセスです。これにより、情報の本質を保ちながらもプライバシーを守ることができます。AIが個別のデータに基づいてではなく、パターンや傾向に基づいた判断を行うための手法です。
具体例: 個人の詳細な履歴を使用する代わりに、統計的なデータや一般化された情報を使用して分析を行うことで、個人を特定するリスクを減らします。<br><br>
<strong>3. 表現の適正化</strong><br>
重要性: 生成AIがアウトプットする情報の表現が適切であることは、誤解を避け、正確な情報伝達を確保するために必要です。特に、生成された情報が不正確であったり、誤解を招く表現であった場合、利用者や社会に悪影響を与える可能性があります。
具体例: AIが生成するテキストやレポートが誤解を招かないように、分かりやすく、かつ適切なコンテキストで表現されているかを確認・修正するプロセスです。
""", unsafe_allow_html=True)

st.markdown("---")
# タイトル
st.markdown("""
<h1 style='font-size:18px; margin-bottom: 5px;'>野良GPT</h1>
""", unsafe_allow_html=True)

with st.expander("詳細を表示"):
    st.markdown("""
「野良GPT」という概念が指すのは、正式な管理や規制を受けていない生成AIモデルのことを意味します。
このようなAIは、正式なプラットフォームや信頼できる組織によって運営されておらず、リスクが多く存在します。具体的には、以下のようなリスクが考えられます。

1. 情報漏洩のリスク
個人情報や機密情報の漏洩: 野良GPTは、適切なセキュリティ対策が取られていない可能性が高く、利用者が入力した個人情報や機密情報が不正に利用されたり、外部に漏洩するリスクがあります。
データ保護の欠如: 信頼できる管理体制がない場合、データ保護規制（GDPRなど）に違反する可能性も高まります。これにより、個人データが不適切に収集・保存されるリスクがあります。
2. 誤情報の生成
精度の低い情報: 野良GPTは、適切に訓練されていなかったり、メンテナンスが不十分である可能性があるため、誤った情報や偏りのあるコンテンツを生成することが考えられます。これにより、誤情報が拡散し、利用者が誤解を招く行動を取るリスクが高まります。
悪意のあるコンテンツ: 生成AIが意図せず攻撃的なコンテンツや有害なメッセージを生成することがあり、それが意図的に拡散される可能性も存在します。
3. 知的財産権侵害のリスク
著作権侵害: 野良GPTが訓練に使用したデータが適切にライセンスされていなかったり、コンテンツ生成において他者の知的財産権を侵害するリスクがあります。このようなモデルを利用すると、著作権や商標権の侵害に巻き込まれる可能性があります。
法的責任の不明確さ: 野良GPTは運営者が不透明であったり、利用規約が不十分なことが多いため、問題が発生した際に誰が責任を負うのかが不明確です。これにより、ユーザーが法的なリスクを負う可能性があります。
4. セキュリティリスク
マルウェアやハッキングのリスク: 野良GPTは、悪意のある攻撃者によって利用される可能性があり、ユーザーがモデルを使用する際にマルウェアが仕込まれたり、データが盗まれるリスクがあります。
サービス停止や不安定性: 野良GPTは、信頼できるインフラを持たないことが多く、突然のサービス停止やデータ消失など、信頼性の欠如が問題となります。
5. 倫理的なリスク
偏見や差別の拡散: 野良GPTは、正式なチェックやフィルタリングが行われないため、学習データに含まれる偏見や差別的な要素がそのまま生成され、社会に悪影響を与える可能性があります。
フェイクニュースの生成と拡散: 野良GPTが誤情報やフェイクニュースを生成し、それが拡散されることで、社会全体に混乱や誤解を招く危険性があります。<br><br>
まとめ
「野良GPT」は、管理が不十分であるため、情報漏洩、誤情報の生成、知的財産権の侵害、セキュリティリスク、倫理的問題といった複数のリスクを抱えています。
こうしたリスクを軽減するためには、信頼できるプラットフォームで管理されたAIモデルを使用し、適切な規制とガイドラインに従うことが重要です。
""", unsafe_allow_html=True)
    st.markdown("---")

st.markdown("""
<h1 style='font-size:18px; margin-bottom: 5px;'>参考サイト</h1>
""", unsafe_allow_html=True)
    st.markdown("""
1. [経済産業省 AI事業者ガイドライン(1.0版)]
(https://www.meti.go.jp/press/2024/04/20240419004/20240419004.html) （更新日：
2024年4月19日）
""")
